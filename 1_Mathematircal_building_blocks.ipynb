{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color=\"darkgreen\">\n",
    "# Lecture 1. Mathematical Building Blocks of Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 MNIST data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](figures/mnist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 딥러닝의 \"Hellow world\" \n",
    "- 흑백 손글씨 숫자 이미지($28\\times 28$ 픽셀)를 0-9까지 10개의 범주로 구분해놓은 데이터셋\n",
    "- 6만개 training set, 1 만개 test set으로 구성  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T09:46:35.345000Z",
     "start_time": "2019-03-08T09:46:33.309667Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T09:46:35.358094Z",
     "start_time": "2019-03-08T09:46:35.346882Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T09:46:35.365561Z",
     "start_time": "2019-03-08T09:46:35.359736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T09:46:35.373023Z",
     "start_time": "2019-03-08T09:46:35.367411Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T09:46:35.379848Z",
     "start_time": "2019-03-08T09:46:35.374823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T09:46:35.386941Z",
     "start_time": "2019-03-08T09:46:35.381794Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T09:46:35.395947Z",
     "start_time": "2019-03-08T09:46:35.389046Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Workflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T09:46:35.442798Z",
     "start_time": "2019-03-08T09:46:35.397820Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fully connected layer 두 개가 연결된 모형을 구축\n",
    "- 마지막 layer는 10개의 확률 점수가 들어있는 배열을 반환하는 softmax activation을 사용하여 0-9의 숫자 클래스에 들어갈 확률을 예측 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T09:46:37.421420Z",
     "start_time": "2019-03-08T09:46:37.371391Z"
    }
   },
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `loss function`:  모형의 성능을 측정하는 방법으로 네트워크가 옳은 방향으로 학습될 수 있도록 만들어줌 \n",
    "- `optimizer`: input data를 기반으로  loss function을 최소화 시키도록 weight를 업데이트하는 메커니즘 \n",
    "- `metrics`: training/test 과정을 모니터링할 지표 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Preparing the image data and the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T09:46:39.765619Z",
     "start_time": "2019-03-08T09:46:39.413374Z"
    }
   },
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터를 네트워크에 맞는 크기로 바꿈 \n",
    "- 모든 값을 0과 1사이의 값으로 변환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T09:46:40.504187Z",
     "start_time": "2019-03-08T09:46:40.490863Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 레이블을 범주형으로 인코딩(one-hot encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T09:50:21.570524Z",
     "start_time": "2019-03-08T09:47:34.038642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0079 - acc: 0.9978\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0061 - acc: 0.9983\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0049 - acc: 0.9986\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0039 - acc: 0.9989\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0032 - acc: 0.9991\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0025 - acc: 0.9994\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0020 - acc: 0.9996\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0016 - acc: 0.9996\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0015 - acc: 0.9996\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0012 - acc: 0.9997\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 9.6616e-04 - acc: 0.9998\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 9.2227e-04 - acc: 0.9998\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 8.2292e-04 - acc: 0.9999\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 5.8056e-04 - acc: 0.9999\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 6.2185e-04 - acc: 0.9999\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 5.8066e-04 - acc: 0.9999\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 5.0711e-04 - acc: 0.9999\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 4.2051e-04 - acc: 1.0000\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 4.4614e-04 - acc: 0.9999\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 3.9387e-04 - acc: 1.0000\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 4.7216e-04 - acc: 0.9999\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 5.0365e-04 - acc: 0.9999\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 3.7621e-04 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 3.0282e-04 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 3.1762e-04 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 3.2210e-04 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 3.2518e-04 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.8642e-04 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 2.7838e-04 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.6994e-04 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.6951e-04 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.7137e-04 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 2.6922e-04 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.6886e-04 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.6879e-04 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 2.6877e-04 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 2.6877e-04 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 2.6877e-04 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.6876e-04 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.6875e-04 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.6875e-04 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.6875e-04 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.6875e-04 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.6875e-04 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.6875e-04 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.6875e-04 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.6875e-04 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.6875e-04 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.6875e-04 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.6875e-04 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.6875e-04 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.6875e-04 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.6875e-04 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.6875e-04 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 2.6875e-04 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.6875e-04 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.6875e-04 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f97f2ef9828>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=100, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 훈련하는 동안 loss와 accuracy가 출력됨 \n",
    "- 60000개의 데이터셋을 총 5번 사용하는 만큼(epoch=5) 훈련을 지속 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (5) Prediction for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T09:50:32.384899Z",
     "start_time": "2019-03-08T09:50:31.919220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 46us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T09:50:32.895998Z",
     "start_time": "2019-03-08T09:50:32.890403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 0.9844\n"
     ]
    }
   ],
   "source": [
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test set에 대한 accuracy가 0.9799로 training set에 대한 accuracy보다 약간 낮음 (overfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Data representations for neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tensor: 데이터를 위한 컨테이나\n",
    "- 행렬의 일반화된 형태 \n",
    "- 차원을 axis라고 부름 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalar (0D tensor)\n",
    "- 하나의 숫자만 담고 있는 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T12:33:31.616137Z",
     "start_time": "2019-02-12T12:33:31.608291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(12)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x=np.array(12)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T12:33:49.844603Z",
     "start_time": "2019-02-12T12:33:49.838050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectors (1D tensor)\n",
    "- 하나의 axis를 가지는 벡터 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T12:35:16.294973Z",
     "start_time": "2019-02-12T12:35:16.287844Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.array([12,3,6,14,7])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `x`는 5-dimensional vector (5D tensor가 아님)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrices (2D tensors)\n",
    "- 2개의 axis가 있음: row, column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T13:08:42.206703Z",
     "start_time": "2019-02-12T13:08:42.193596Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[5, 78, 2, 34, 0],\n",
    "              [6, 79, 3, 35, 1],\n",
    "              [7, 80, 4, 36, 2]])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1st axis: row\n",
    "- 2nd axis: column \n",
    "- 1st row = `[5, 78, 2, 34, 0]`\n",
    "- 1st column = `[5,6,7]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3D tensors and higher-dimensional tensors\n",
    "- 행렬들을 모아 하나의 array로 만들면 직육면체의 3D tensor가 만들어짐 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T12:43:44.767540Z",
     "start_time": "2019-02-12T12:43:44.751013Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],\n",
    "              [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],\n",
    "              [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]]])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key attributes\n",
    "- rank(axis의 개수)\n",
    "    - 3D tensor의 rank는 3\n",
    "    - 2D tensor의 rank는 2\n",
    "    - `ndim` 속성에 저장 \n",
    "- shape\n",
    "    - Tensor의 각 axis를 따라 얼마나 많은 차원이 있는지를 나타낸 tuple \n",
    "    - 위의 2D tensor의 shape은 (3,5)\n",
    "    - 위의 3D tensor의 shape은 (3,3,5)\n",
    "- data type\n",
    "    - Tensor에 포함된 데이터의 타입\n",
    "    - float32, uint8, float64 등\n",
    "    - `dtype` 속성에 저장\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T13:18:05.178472Z",
     "start_time": "2019-02-12T13:18:04.788817Z"
    }
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">_TO DO: MNIST 데이터_\n",
    "    \n",
    "1. train_images의 rank는?\n",
    "2. train_images의 shape은?\n",
    "3. train_images의 data type은?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T14:11:23.127447Z",
     "start_time": "2019-02-12T14:11:22.934573Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit = train_images[4]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples of tensor data\n",
    "- Vector data—2D tensors of shape (samples, features)\n",
    "    - 사람의 나이, 우편번호, 소득으로 구성된 인구통계 데이터. 10만명이 포함된 데이터 셋이라면 (100000,3) \n",
    "    - 공통 단어 2만 개로 이루어진 텍스트 문서 500개가 있다. 하나의 문서를 각 단어가 등장한 횟수로 표현된 벡터로 나타낸다면 (500,20000)\n",
    "- Timeseries data or sequence data—3D tensors of shape (samples, timesteps, features)\n",
    "    ![image.png](figures/timeseries.PNG)\n",
    "    \n",
    "    - 관례적으로 시간은 axis=1인 축으로 표현 \n",
    "    - 주식가격 데이터셋: 1분 마다 3개의 feature(현재 주식가격, 지난 1분 동안 최고 가격, 최저 가격)를 저장. 1분마다 3-dimensional vector 생성. 하루의 거래는 (390,3) 크기의 2D tensor로 저장. 250일치 데이터는 (250,390,3) 크기의 3D tensor로 저장\n",
    "    - 트윗 데이터셋: 각 트윗은 128개의 알파벳/문자로 구성된 280개의 문자 시퀀스. 하나의 트윗은 (280,128) 크기의 2D tensor. 100만개의 트윗이 포함된 데이터는 (1000000,280,128) 크기의 3D tensor\n",
    "- Images—4D tensors of shape (samples, height, width, channels) \n",
    "\n",
    "    ![image.png](figures/4d_image.PNG)\n",
    "    -  하나의 이미지는 전형적으로 높이, 너비, 컬러채널의 3-dimensional data. $256\\times 256$ 픽셀의 이미지라면 (256, 256, 3) 크기의 3D tensor\n",
    "    - 128개의 이미지가 포함된 batch는 (128, 256, 256, 3) 크기의 4D tensor로 표현 \n",
    "    - 만일 흑백 이미지라면 (128, 256, 256, 1)\n",
    "\n",
    "- Video—5D tensors of shape (samples, frames, height, width, channels)\n",
    "    - 비디오 데이터는 이미지의 연속 \n",
    "    - 60초 짜리 $144 \\times 256$ 유튜브 비디오 클립을 초당 4프레임으로 샘플링하면 240 프레임을 생성. 하나의 비디오 클립은 (240, 144, 256, 3)\n",
    "    - 비디오 클립을 4개 포함한 batch는 (4, 240, 144, 256, 3) 크기의 5D tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">_TO DO: _\n",
    "    \n",
    "영화 리뷰 25000개가 있다. 각 리뷰는 200개의 단어로 이루어져 있다. \n",
    "- 가장 자주 등장하는 10000개의 단어에 대해 각 리뷰에 해당 단어의 포함 유무를 0/1 로 나타낸다. 이 데이터의  shape은 무엇인가? \n",
    "- 가장 자주 등장하는 10000개에 대해 각 단어를 one-hot vector로 표현하여 하나의 문장을 matrix로 표현한다. 이 데이터의 shape은 무엇인가? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "__References__\n",
    "\n",
    "\n",
    "- [Deep Learning with Python, François Chollet,](https://www.manning.com/books/deep-learning-with-python)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
